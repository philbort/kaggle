{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Class_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>-0.136095</td>\n",
       "      <td>-0.229728</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.206510</td>\n",
       "      <td>0.551066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.166305</td>\n",
       "      <td>0.272966</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.428790</td>\n",
       "      <td>0.405028</td>\n",
       "      <td>0.497665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.494750</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.231250</td>\n",
       "      <td>-0.420896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.355458</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>-0.190000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived         Age        Fare      Gender  \\\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean    446.000000    0.383838   -0.136095   -0.229728    0.647587   \n",
       "std     257.353842    0.486592    0.166305    0.272966    0.477990   \n",
       "min       1.000000    0.000000   -0.494750   -0.500000    0.000000   \n",
       "25%     223.500000    0.000000   -0.231250   -0.420896    0.000000   \n",
       "50%     446.000000    0.000000   -0.175000   -0.355458    1.000000   \n",
       "75%     668.500000    1.000000   -0.050000   -0.190000    1.000000   \n",
       "max     891.000000    1.000000    0.500000    0.500000    1.000000   \n",
       "\n",
       "          Class_1     Class_2     Class_3  \n",
       "count  891.000000  891.000000  891.000000  \n",
       "mean     0.242424    0.206510    0.551066  \n",
       "std      0.428790    0.405028    0.497665  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    1.000000  \n",
       "75%      0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_clean_data(csv_file):\n",
    "    df = pd.read_csv(csv_file, header = 0)\n",
    "    # One hot encoding for \"Sex\"\n",
    "    df['Gender'] = df['Sex'].map({'female':0, 'male':1}).astype(int)\n",
    "    # Get median ages per \"Gender\" and \"Pclass\"\n",
    "    median_ages = np.zeros((2,3))\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            median_ages[i,j] = df[(df['Gender'] == i) &\n",
    "                                  (df['Pclass'] == j+1)]['Age'].dropna().median()\n",
    "    # Fill in median age for missing \"Age\"\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            df.loc[ (df.Age.isnull()) & (df.Gender == i) & \n",
    "                   (df.Pclass == j+1),'Age'] = median_ages[i,j]\n",
    "    # Normalize \"Age\"\n",
    "    df['Age'] = (df['Age'] - 40)/80\n",
    "    # Normalize \"Fare\"\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "    df.loc[df['Fare'] > 100,'Fare'] = 100\n",
    "    df['Fare'] = (df['Fare'] - 50)/100\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')\n",
    "    df = df.drop(['SibSp','Parch','Name','Sex','Ticket','Cabin','Embarked'],axis=1)\n",
    "    # One hot encoding for \"Pclass\"\n",
    "    df = df.join(pd.get_dummies(df['Pclass'], prefix ='Class').astype(int))\n",
    "    df = df.drop(['Pclass'], axis = 1)\n",
    "    return df\n",
    "train_df = load_clean_data('data/train.csv')\n",
    "test_df = load_clean_data('data/test.csv')\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_data = train_df.drop(['PassengerId', \"Survived\"], axis = 1)\n",
    "y_data = train_df['Survived']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note on random forest:\n",
    "Random forest may need float numbers as input. As a result, one hot encoding on \"Pclass\" may not be helpful here.\n",
    "However, I didn't see performance improvement if I get rid of one hot encoding. Need to revisit this in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training dataset: 0.980337078652\n",
      "Score on validation dataset: 0.787709497207\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(x_train, y_train)\n",
    "print(\"Score on training dataset:\", random_forest.score(x_train, y_train))\n",
    "print(\"Score on validation dataset:\", random_forest.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = test_df.drop(['PassengerId'], axis = 1)\n",
    "y_pred = random_forest.predict(test_data)\n",
    "submission = pd.DataFrame({ \"PassengerId\":test_df['PassengerId'],\n",
    "                             \"Survived\":y_pred })\n",
    "submission.to_csv('random_forest.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try some SVC methods below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training dataset: 0.794943820225\n",
      "Score on validation dataset: 0.759776536313\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel = 'poly')\n",
    "svc.fit(x_train, y_train)\n",
    "print(\"Score on training dataset:\", svc.score(x_train, y_train))\n",
    "print(\"Score on validation dataset:\", svc.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
